{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3817cdf3-6f92-4d56-807d-d67a187ad617",
   "metadata": {},
   "source": [
    "<center><h1>Основы глубокого обучение</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c536aa43-b3b7-4421-b12c-cad3d20a46ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.8\n"
     ]
    }
   ],
   "source": [
    "!python -V # Версия Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794dc847-eb8f-4f73-a769-5c42c406a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подавление предупреждений\n",
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "# Импорт необходимых библиотек\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import sklearn\n",
    "import networkx as nx\n",
    "import jupyterlab as jlab\n",
    "import ipywidgets\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from torch import Tensor\n",
    "from einops import rearrange\n",
    "from typing import Tuple, Callable\n",
    "from torch.autograd import Function\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f74cb53-2804-49f6-a502-e92a6399c25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>№</th><th>Библиотека</th><th>Версия</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Torch&quot;</td><td>&quot;2.2.2&quot;</td></tr><tr><td>2</td><td>&quot;NumPy&quot;</td><td>&quot;1.26.4&quot;</td></tr><tr><td>3</td><td>&quot;Polars&quot;</td><td>&quot;1.19.0&quot;</td></tr><tr><td>4</td><td>&quot;Pandas&quot;</td><td>&quot;2.2.3&quot;</td></tr><tr><td>5</td><td>&quot;Matplotlib&quot;</td><td>&quot;3.10.0&quot;</td></tr><tr><td>6</td><td>&quot;Yfinance&quot;</td><td>&quot;0.2.51&quot;</td></tr><tr><td>7</td><td>&quot;Scikit-learn&quot;</td><td>&quot;1.6.1&quot;</td></tr><tr><td>8</td><td>&quot;Ipywidgets&quot;</td><td>&quot;8.1.5&quot;</td></tr><tr><td>9</td><td>&quot;JupyterLab&quot;</td><td>&quot;4.3.4&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 3)\n",
       "┌─────┬──────────────┬────────┐\n",
       "│ №   ┆ Библиотека   ┆ Версия │\n",
       "│ --- ┆ ---          ┆ ---    │\n",
       "│ i64 ┆ str          ┆ str    │\n",
       "╞═════╪══════════════╪════════╡\n",
       "│ 1   ┆ Torch        ┆ 2.2.2  │\n",
       "│ 2   ┆ NumPy        ┆ 1.26.4 │\n",
       "│ 3   ┆ Polars       ┆ 1.19.0 │\n",
       "│ 4   ┆ Pandas       ┆ 2.2.3  │\n",
       "│ 5   ┆ Matplotlib   ┆ 3.10.0 │\n",
       "│ 6   ┆ Yfinance     ┆ 0.2.51 │\n",
       "│ 7   ┆ Scikit-learn ┆ 1.6.1  │\n",
       "│ 8   ┆ Ipywidgets   ┆ 8.1.5  │\n",
       "│ 9   ┆ JupyterLab   ┆ 4.3.4  │\n",
       "└─────┴──────────────┴────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Версии необходимых библиотек\n",
    "packages = [\n",
    "    \"Torch\", \"NumPy\", \"Polars\", \"Pandas\", \"Matplotlib\", \"Yfinance\", \"Scikit-learn\", \"Ipywidgets\", \"JupyterLab\"\n",
    "]\n",
    "\n",
    "package_objects = [\n",
    "    torch, np, pl, pd, mpl, yf, sklearn, ipywidgets, jlab\n",
    "]\n",
    "\n",
    "versions = list(map(lambda obj: obj.__version__, package_objects))\n",
    "\n",
    "columns_order = [\"№\", \"Библиотека\", \"Версия\"]\n",
    "df_pkgs = (\n",
    "    pl.DataFrame({\n",
    "        columns_order[1]: packages,\n",
    "        columns_order[2]: versions\n",
    "    })\n",
    "    .with_columns(pl.arange(1, pl.lit(len(packages)) + 1).alias(columns_order[0]))\n",
    "    .select(columns_order)\n",
    ")\n",
    "\n",
    "display(df_pkgs)\n",
    "\n",
    "path2reqs = \".\"\n",
    "reqs_name = \"requirements.txt\"\n",
    "\n",
    "def get_packages_and_versions():\n",
    "    \"\"\"Генерация строк с библиотеками и их версиями в формате: библиотека==версия\"\"\"\n",
    "    \n",
    "    for package, version in zip(packages, versions):\n",
    "        yield f\"{package.lower()}=={version}\\n\"\n",
    "\n",
    "with open(os.path.join(path2reqs, reqs_name), \"w\", encoding = \"utf-8\") as f:\n",
    "    f.writelines(get_packages_and_versions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61dc6d-db97-4798-84c9-d4c4844f8275",
   "metadata": {},
   "source": [
    "# Лекция 5\n",
    "\n",
    "4. **Современные архитектуры глубокого обучения**\n",
    "    - Обзор семейства Mamba\n",
    "    - Применение данных архитектур для анализа последовательных данных, изображений и мультимодальной интеграции"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a95abbbe-e9da-4438-a294-7cbdc283b1ef",
   "metadata": {},
   "source": [
    "![5_1.png](https://raw.githubusercontent.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/refs/heads/main/tutorials/imgs/5_1.png)\n",
    "\n",
    "### Ограничения трансформеров\n",
    "\n",
    "Трансформеры стали стандартом в глубоких нейросетях для обработки последовательных данных, таких как текст, аудио и видео. Несмотря на их успех в ряде задач, существует несколько существенных ограничений, которые мешают их эффективному применению в ряде случаев:\n",
    "\n",
    "1. **Квадратичная сложность вычислений по длине последовательности** $O(L^2)$\n",
    "    - Это означает, что для каждой пары элементов последовательности вычисляются зависимости. В случае длинных последовательностей, например, текстов, размерность входных данных может стать чрезвычайно большой, что приводит к высокой вычислительной нагрузке\n",
    "2. **Ограниченный контекст**\n",
    "    - Трансформеры часто ограничены максимальной длиной контекста, который они могут обрабатывать за один раз, что требует разделения длинных последовательностей на более короткие фрагменты\n",
    "    - Также, для эффективного инференса часто требуется кеширование состояний предыдущих шагов, что увеличивает затраты памяти\n",
    "3. **Высокие требования к аппаратным ресурсам**\n",
    "    - Для обучения трансформеров требуется много ресурсов, включая большое количество вычислительных ядер и высокоскоростные графические процессоры (GPU). Это делает обучение трансформеров затратным и ограничивает их использование в задачах с ограниченными ресурсами\n",
    "\n",
    "### Structured State Space Models (SSM)\n",
    "\n",
    "SSM - это семейство нейросетевых моделей, использующих пространство состояний для моделирования зависимостей в последовательных данных. SSM могут быть более эффективными по сравнению с трансформерами в ряде задач, благодаря нескольким ключевым свойствам:\n",
    "\n",
    "1. **Линейная сложность $O(L)$ по длине последовательности**\n",
    "    - В отличие от трансформеров, где сложность растет квадратично с увеличением длины последовательности, модели SSM имеют линейную сложность, что позволяет работать с длинными последовательностями намного быстрее\n",
    "2. **Гибкость**:\n",
    "    - Модели SSM могут моделировать как временные, так и пространственные зависимости, что делает их подходящими для различных типов данных, включая текст, аудио и видео\n",
    "3. **Хорошая обобщаемость**:\n",
    "    - Модели SSM показывают высокую обобщаемость на различных модальностях, что позволяет использовать их не только для обработки текста, но и для анализа аудио и видео данных\n",
    "  \n",
    "![5_2.png](https://raw.githubusercontent.com/DmitryRyumin/HSE_Fundamentals_of_DL_2025/refs/heads/main/tutorials/imgs/5_2.png)\n",
    "\n",
    "### Математическая основа SSM и Mamba\n",
    "\n",
    "SSM представляют собой классические модели управления, которые могут быть описаны системой дифференциальных уравнений. На дискретном времени они представляют собой:\n",
    "\n",
    "**Уравнение состояния SSM**\n",
    "\n",
    "$$\n",
    "h_t = A h_{t-1} + B x_t\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $h_t$ - скрытое состояние модели в момент времени $t$, которое содержит информацию о предыдущих входных данных и их изменениях\n",
    "- $A$ - матрица перехода, которая описывает, как предыдущее состояние $h_{t-1}$ влияет на текущее состояние $h_t$\n",
    "- $B$ - матрица входных данных, которая описывает, как входные данные $x_t$ влияют на скрытое состояние модели\n",
    "- $x_t$ - входные данные на шаге $t$\n",
    "\n",
    "**Уравнение выхода SSM**\n",
    "\n",
    "$$\n",
    "y_t = C h_t\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $y_t$ - выход модели в момент времени $t$, который получается путем применения матрицы $C$ к скрытому состоянию $h_t$. Это позволяет получить предсказания модели на основе скрытых представлений данных\n",
    "\n",
    "**Дискретизация SSM**\n",
    "\n",
    "В случае работы с дискретными данными, необходимо адаптировать SSM для дискретизации состояния. Это необходимо для корректной работы модели с последовательностями данных, где обновления состояния происходят на каждом шаге времени. Для дискретизации применяется следующий метод\n",
    "\n",
    "$$\n",
    " A_d = e^{\\Delta A}, \\quad B_d = (A^{-1} (e^{\\Delta A} - I)) B\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $\\Delta$ - шаг дискретизации, который определяет, как часто обновляется скрытое состояние\n",
    "- $e^{\\Delta A}$ - экспоненциальная функция, которая позволяет получить дискретизированную матрицу перехода\n",
    "- $I$ - единичная матрица, используемая для вычислений\n",
    "\n",
    "Этот метод дискретизации позволяет сохранить важные свойства модели, такие как ее устойчивость и способность к долгосрочному запоминанию контекста, при этом не требуя сложных вычислений\n",
    "\n",
    "### Механизм выбора (Selection Mechanism)\n",
    "\n",
    "Одним из ключевых нововведений в Mamba является механизм выбора (Selection Mechanism), который заменяет self-attention и делает вычисления более эффективными. Этот механизм позволяет модели:\n",
    "\n",
    "1. **Адаптивно запоминать или забывать информацию**\n",
    "    - Модель может динамически регулировать, какие части последовательности должны быть запомнены, а какие - забыты в зависимости от значимости входных данных на текущем шаге\n",
    "2. **Избежать необходимости в self-attention**\n",
    "    - В отличие от трансформеров, где для обработки каждой пары элементов последовательности требуется вычисление внимания (self-attention), Mamba использует механизм выбора, который позволяет получать схожие результаты, но с линейной сложностью $O(L)$\n",
    "3. **Обеспечить линейную сложность вычислений**\n",
    "    - Несмотря на использование адаптивных параметров и динамическое обновление скрытых состояний, вычисления остаются линейными по сложности, что делает Mamba эффективным решением для работы с длинными последовательностями данных\n",
    "\n",
    "### Преимущества механизма выбора\n",
    "\n",
    "- **Адаптивность** позволяет модели динамически переключаться между долгосрочным запоминанием и забыванием\n",
    "- **Эффективность** за счет линейной сложности $O(L)$ по длине последовательности, что значительно сокращает вычислительные затраты\n",
    "- **Отказ от self-attention** снижает вычислительные расходы за счёт замены сложных операций внимания на более простые рекуррентные вычисления\n",
    "\n",
    "### Формализованная интерпретация механизма выбора в Mamba\n",
    "\n",
    "Механизм выбора в Mamba можно интерпретировать как обобщение механизма затворов в RNN. В RNN, механизм затворов управляет процессом обновления скрытых состояний. Например:\n",
    "\n",
    "$$\n",
    "g_t = \\sigma(W x_t + U h_{t-1})\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t = g_t \\cdot h_{t-1} + (1 - g_t) \\cdot x_t\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $g_t$ - это затвор, который регулирует, сколько информации из предыдущего состояния $h_{t-1}$ будет сохранено, а сколько - заменено новым входом $x_t$\n",
    "- $\\sigma$ - это сигмоида, которая ограничивает значения $g_t$ в интервале от 0 до 1\n",
    "\n",
    "В механизме выбора Mamba, аналогичные принципы используются для адаптивного контроля обновлений состояния, но с более гибкими параметрами, зависящими от входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721882d3-9f61-49a6-b161-8b5ebae8c84d",
   "metadata": {},
   "source": [
    "### Как Mamba реализует механизм выбора эффективно с точки зрения вычислений?\n",
    "\n",
    "Механизм выбора в Mamba - это ключевая особенность, которая позволяет моделям работать с длинными последовательностями данных, избегая необходимости в затратном self-attention, сохраняя линейную сложность вычислений по длине последовательности ($O(L)$)\n",
    "\n",
    "#### Параметризация механизма выбора\n",
    "\n",
    "Механизм выбора в Mamba использует параметризацию, которая позволяет динамически адаптировать процессы запоминания и забывания в зависимости от входных данных на каждом шаге. Это может быть сделано через:\n",
    "\n",
    "- **Затворы (gates)**: аналогично RNN, где используются функции активации (например, сигмоида) для вычисления веса, с которым предыдущее состояние будет смешано с новым входом. Вместо того, чтобы работать с фиксированным набором параметров, Mamba использует динамическое вычисление этих весов в зависимости от текущего контекста\n",
    "- **Адаптивные веса**: весовое значение для каждого шага вычисляется адаптивно, что позволяет модели больше или меньше запоминать информации в зависимости от её значимости.\n",
    "\n",
    "#### Линейная сложность $O(L)$\n",
    "\n",
    "При использовании рекуррентных вычислений обновление состояния происходит за один шаг для каждого элемента последовательности. На каждый шаг $t$ необходимо лишь вычислить скрытое состояние $h_t$ на основе предыдущего состояния $h_{t-1}$ и текущего входа $x_t$. Эти вычисления происходят за $O(1)$ для каждого шага, что дает общую сложность $O(L)$ по длине последовательности\n",
    "\n",
    "Это отличие от квадратичной сложности в трансформерах делает Mamba гораздо более эффективным для работы с длинными последовательностями\n",
    "\n",
    "#### Обработка длинных последовательностей\n",
    "\n",
    "Механизм выбора позволяет динамически выбирать, какая информация важна для долгосрочного запоминания, а какая может быть забыта. Это достигается путем адаптивной модификации состояния в зависимости от входных данных. В отличие от трансформеров, где для каждого шага обновляется внимание на все элементы, Mamba обновляет только релевантные состояния, минимизируя вычислительные затраты\n",
    "\n",
    "- **Долгосрочное запоминание**: на основе адаптивного механизма модель решает, что важно запомнить на длинных отрезках, обеспечивая качественное извлечение информации, даже из длинных контекстов\n",
    "- **Забывание ненужных данных**: если какие-то данные или контексты оказываются несущественными для текущей задачи, механизм выбора позволяет их игнорировать, что снижает избыточность вычислений\n",
    "\n",
    "#### Параллелизация на GPU\n",
    "\n",
    "Использование рекуррентных вычислений с линейной сложностью значительно облегчает параллелизацию вычислений на GPU. В отличие от трансформеров, где для каждого шага нужно обрабатывать все токены с помощью attention, в Mamba можно параллельно обрабатывать несколько элементов последовательности, что ускоряет обучение и инференс\n",
    "\n",
    "- **Параллелизация состояний**: поскольку каждый шаг $t$ вычисляется независимо от других с помощью рекуррентных вычислений, то можно параллельно обновлять несколько слоёв или несколько последовательностей, используя мощность современных графических процессоров\n",
    "  \n",
    "- **Меньше памяти**: также важным аспектом является то, что для работы с рекуррентными вычислениями требуется меньше памяти, чем для self-attention. Это позволяет использовать модели на более дешёвых GPU или ускоряет работу на существующих платформах\n",
    "\n",
    "#### Гибкость и адаптивность\n",
    "\n",
    "Механизм выбора может быть дополнительно адаптирован для разных типов данных (например, текст, аудио, видео). Это означает, что модель может динамически регулировать, какие части последовательности являются наиболее важными, и на каких этапах требуется запоминание или забывание, что делает её более гибкой для различных задач\n",
    "\n",
    "Для работы с текстами модель может использовать одни параметры выбора, для аудио - другие, что позволяет моделям Mamba быть адаптированными к различным типам последовательных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56e4fa-6e01-4145-b828-a3d06a7618b4",
   "metadata": {},
   "source": [
    "### Gated Delta Networks: Улучшение Mamba2 с помощью Delta Rule\n",
    "\n",
    "**Линейные трансформеры** (Mamba2) уменьшают вычислительные затраты, но сталкиваются с проблемами хранения информации. **Gated Delta Networks (Gated DeltaNet)** - новый метод, сочетающий преимущества **Mamba2** и **DeltaNet** для эффективного управления памятью\n",
    "\n",
    "#### Различие между Mamba и Mamba2\n",
    "\n",
    "Mamba2 является улучшенной версией оригинальной Mamba c модификациями\n",
    "\n",
    "| Свойство | Mamba  | Mamba2 |\n",
    "|----------|--------|--------|\n",
    "| Основа | SSM | Улучшенный SSM с динамическим управлением памятью |\n",
    "| Способ обновления состояния | Линейное обновление с фиксированными параметрами | Динамическое обновление с адаптивными весами |\n",
    "| Гибкость обработки информации | Менее адаптивный | Более гибкий за счет использования **взвешенного затухания** |\n",
    "| Эффективность вычислений | Оптимизированный линейный SSM | Оптимизированное рекуррентное обновление с уменьшенной потерей информации |\n",
    "\n",
    "#### Обновление состояния в Mamba2\n",
    "\n",
    "В Mamba2 динамика скрытого состояния происходит через\n",
    "\n",
    "$$\n",
    "h_t = A_t h_{t-1} + B_t x_t\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $A_t$ - адаптивная матрица перехода, изменяемая в зависимости от входных данных\n",
    "- $B_t$ - матрица преобразования входных данных\n",
    "- $x_t$ - входной вектор на шаге $t$\n",
    "\n",
    "Для адаптивного управления состоянием необходимо использовать **обучаемые функции**\n",
    "\n",
    "$$\n",
    "A_t = \\sigma(W_A x_t), \\quad B_t = \\sigma(W_B x_t)\n",
    "$$\n",
    "\n",
    "где $W_A$ и $W_B$ - параметризованные матрицы, а $\\sigma$ - активационная функция (например, сигмоида или ReLU)\n",
    "\n",
    "#### Проблема памяти в линейных трансформерах\n",
    "\n",
    "Линейные трансформеры заменяют механизм self-attention на линейные рекуррентные обновления состояния\n",
    "\n",
    "$$\n",
    "S_t = S_{t-1} + v_t k_t^T.\n",
    "$$\n",
    "\n",
    "Но этот подход имеет ограничения\n",
    "\n",
    "- Количество ортогональных пар ключ-значение ограничено размерностью модели (**коллизия памяти**)\n",
    "- Невозможно выборочно забывать устаревшую информацию (**ограниченная селективность обновлений**)\n",
    "\n",
    "#### Математическая основа Gated Delta Rule\n",
    "\n",
    "Gated DeltaNet использует новый рекуррентный механизм обновления памяти\n",
    "\n",
    "$$\n",
    "S_t = \\alpha_t S_{t-1} (I - \\beta_t k_t k_t^T) + \\beta_t v_t k_t^T,\n",
    "$$\n",
    "\n",
    "где\n",
    "- $\\alpha_t$ - коэффициент затухания, определяющий степень сохранения предыдущей памяти\n",
    "  $$\n",
    "  \\alpha_t = \\sigma(W_\\alpha x_t + b_\\alpha)\n",
    "  $$\n",
    "- $\\beta_t$ - параметр, управляющий заменой старых значений\n",
    "  $$\n",
    "  \\beta_t = \\sigma(W_\\beta x_t + b_\\beta)\n",
    "  $$\n",
    "- $I - \\beta_t k_t k_t^T$ - матрица фильтрации устаревших значений, предотвращающая переполнение памяти\n",
    "\n",
    "Дополнительно используется механизм **нормализации состояния**\n",
    "\n",
    "$$\n",
    "S_t \\leftarrow \\frac{S_t}{\\| S_t \\| + \\epsilon}\n",
    "$$\n",
    "\n",
    "что предотвращает взрывные градиенты и улучшает стабильность обучения\n",
    "\n",
    "#### Аппаратная оптимизация: Chunkwise Parallel Form\n",
    "\n",
    "Для эффективного обучения на GPU используется **chunkwise parallel form**\n",
    "\n",
    "$$\n",
    "S_{t+1} = \\gamma_C S_t + (U_t - W_t S_t^T)^T D K_t\n",
    "$$\n",
    "\n",
    "где $\\gamma_C$ - коэффициент затухания внутри chunkwise. Это направлено на:\n",
    "- **Сохранение линейной сложности** по длине последовательности $O(L)$\n",
    "- **Эффективное использование тензорных ядер** на GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa28bf0f-9c78-48bc-b4e1-6db272bed9dc",
   "metadata": {},
   "source": [
    "# Семинар 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbe4c18d-cbe6-4a23-b59e-4a4e514b4baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 128, 512])\n",
      "Gradients calculated for layers.0.in_proj.weight\n",
      "Gradients calculated for layers.0.in_proj.bias\n",
      "Gradients calculated for layers.0.s_B.weight\n",
      "Gradients calculated for layers.0.s_B.bias\n",
      "Gradients calculated for layers.0.s_C.weight\n",
      "Gradients calculated for layers.0.s_C.bias\n",
      "Gradients calculated for layers.0.out_proj.weight\n",
      "Gradients calculated for layers.0.out_proj.bias\n",
      "Gradients calculated for layers.1.in_proj.weight\n",
      "Gradients calculated for layers.1.in_proj.bias\n",
      "Gradients calculated for layers.1.s_B.weight\n",
      "Gradients calculated for layers.1.s_B.bias\n",
      "Gradients calculated for layers.1.s_C.weight\n",
      "Gradients calculated for layers.1.s_C.bias\n",
      "Gradients calculated for layers.1.out_proj.weight\n",
      "Gradients calculated for layers.1.out_proj.bias\n",
      "Gradients calculated for layers.2.in_proj.weight\n",
      "Gradients calculated for layers.2.in_proj.bias\n",
      "Gradients calculated for layers.2.s_B.weight\n",
      "Gradients calculated for layers.2.s_B.bias\n",
      "Gradients calculated for layers.2.s_C.weight\n",
      "Gradients calculated for layers.2.s_C.bias\n",
      "Gradients calculated for layers.2.out_proj.weight\n",
      "Gradients calculated for layers.2.out_proj.bias\n",
      "Gradients calculated for layers.3.in_proj.weight\n",
      "Gradients calculated for layers.3.in_proj.bias\n",
      "Gradients calculated for layers.3.s_B.weight\n",
      "Gradients calculated for layers.3.s_B.bias\n",
      "Gradients calculated for layers.3.s_C.weight\n",
      "Gradients calculated for layers.3.s_C.bias\n",
      "Gradients calculated for layers.3.out_proj.weight\n",
      "Gradients calculated for layers.3.out_proj.bias\n",
      "Gradients calculated for layers.4.in_proj.weight\n",
      "Gradients calculated for layers.4.in_proj.bias\n",
      "Gradients calculated for layers.4.s_B.weight\n",
      "Gradients calculated for layers.4.s_B.bias\n",
      "Gradients calculated for layers.4.s_C.weight\n",
      "Gradients calculated for layers.4.s_C.bias\n",
      "Gradients calculated for layers.4.out_proj.weight\n",
      "Gradients calculated for layers.4.out_proj.bias\n",
      "Gradients calculated for layers.5.in_proj.weight\n",
      "Gradients calculated for layers.5.in_proj.bias\n",
      "Gradients calculated for layers.5.s_B.weight\n",
      "Gradients calculated for layers.5.s_B.bias\n",
      "Gradients calculated for layers.5.s_C.weight\n",
      "Gradients calculated for layers.5.s_C.bias\n",
      "Gradients calculated for layers.5.out_proj.weight\n",
      "Gradients calculated for layers.5.out_proj.bias\n"
     ]
    }
   ],
   "source": [
    "class PScan(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, A_inp, X_inp):\n",
    "        A, X = A_inp.clone(), X_inp.clone()\n",
    "        A, X = rearrange(A, \"l b d s -> b d l s\"), rearrange(X, \"l b d s -> b d l s\")\n",
    "        PScan._forward(A, X)\n",
    "        ctx.save_for_backward(A.clone(), X)\n",
    "        return rearrange(X, \"b d l s -> b l d s\")\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_inp: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        A, X = ctx.saved_tensors\n",
    "        A = torch.cat((A[:, :, :1], A[:, :, 1:].flip(2)), dim = 2)\n",
    "        grad_out = rearrange(grad_inp, \"b l d s -> b d l s\")\n",
    "        grad_out = grad_out.flip(2)\n",
    "        PScan._forward(A, grad_out)\n",
    "        grad_out = grad_out.flip(2)\n",
    "        Q = torch.zeros_like(X)\n",
    "        Q[:, :, 1:].add_(X[:, :, :-1] * grad_out[:, :, 1:])\n",
    "        return rearrange(Q, \"b d l s -> b l d s\"), rearrange(grad_out, \"b d l s -> b l d s\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _forward(A: Tensor, X: Tensor) -> None:\n",
    "        b, d, l, s = A.shape\n",
    "        num_steps = int(math.log2(l))\n",
    "        Av, Xv = A, X\n",
    "        for _ in range(num_steps):\n",
    "            T = Xv.size(2)\n",
    "            Av, Xv = Av[:, :, :T].reshape(b, d, T // 2, 2, -1), Xv[:, :, :T].reshape(b, d, T // 2, 2, -1)\n",
    "            Xv[:, :, :, 1].add_(Av[:, :, :, 1].mul(Xv[:, :, :, 0]))\n",
    "            Av[:, :, :, 1].mul_(Av[:, :, :, 0])\n",
    "            Av, Xv = Av[:, :, :, 1], Xv[:, :, :, 1]\n",
    "        for k in range(num_steps - 1, -1, -1):\n",
    "            Av, Xv = A[:, :, 2**k - 1 : l : 2**k], X[:, :, 2**k - 1 : l : 2**k]\n",
    "            T = 2 * (Xv.size(2) // 2)\n",
    "            if T < Xv.size(2):\n",
    "                Xv[:, :, -1].add_(Av[:, :, -1].mul(Xv[:, :, -2]))\n",
    "                Av[:, :, -1].mul_(Av[:, :, -2])\n",
    "            Av, Xv = Av[:, :, :T].reshape(b, d, T // 2, 2, -1), Xv[:, :, :T].reshape(b, d, T // 2, 2, -1)\n",
    "            Xv[:, :, 1:, 0].add_(Av[:, :, 1:, 0].mul(Xv[:, :, :-1, 1]))\n",
    "            Av[:, :, 1:, 0].mul_(Av[:, :, :-1, 1])\n",
    "\n",
    "pscan: Callable[[Tensor, Tensor], Tensor] = PScan.apply\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d_model: int, eps: float = 1e-8) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(d_model))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:        \n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim = True) + self.eps) * self.weight\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, d_input, d_model):\n",
    "        super(MambaBlock, self).__init__()\n",
    "        self.in_proj = nn.Linear(d_input, d_model)\n",
    "        self.s_B = nn.Linear(d_model, d_model)\n",
    "        self.s_C = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_input)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_proj(x)\n",
    "        B, C = self.s_B(x), self.s_C(x)\n",
    "        return self.out_proj(x + B + C)\n",
    "\n",
    "class Mamba(nn.Module):\n",
    "    def __init__(self, num_layers, d_input, d_model):\n",
    "        super(Mamba, self).__init__()\n",
    "        self.layers = nn.ModuleList([MambaBlock(d_input, d_model) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, seq):\n",
    "        for mamba in self.layers:\n",
    "            seq = mamba(seq)\n",
    "        return seq\n",
    "\n",
    "model = Mamba(num_layers = 6, d_input = 512, d_model = 256)\n",
    "\n",
    "input_tensor = torch.randn(32, 128, 512)\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "target = torch.randn(32, 128, 512)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"Gradients calculated for {name}\")\n",
    "    else:\n",
    "        print(f\"No gradients for {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a0ed4dc-0499-49ca-8702-75b8a028ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.0016543865203857\n",
      "Epoch 2/100, Loss: 1.0013811588287354\n",
      "Epoch 3/100, Loss: 0.9985916614532471\n",
      "Epoch 4/100, Loss: 0.9974302649497986\n",
      "Epoch 5/100, Loss: 0.9964042901992798\n",
      "Epoch 6/100, Loss: 0.9952939748764038\n",
      "Epoch 7/100, Loss: 0.9941698312759399\n",
      "Epoch 8/100, Loss: 0.9929973483085632\n",
      "Epoch 9/100, Loss: 0.9918174743652344\n",
      "Epoch 10/100, Loss: 0.9906189441680908\n",
      "Epoch 11/100, Loss: 0.9894289374351501\n",
      "Epoch 12/100, Loss: 0.9882356524467468\n",
      "Epoch 13/100, Loss: 0.9870733618736267\n",
      "Epoch 14/100, Loss: 0.985882043838501\n",
      "Epoch 15/100, Loss: 0.9847323298454285\n",
      "Epoch 16/100, Loss: 0.9835975766181946\n",
      "Epoch 17/100, Loss: 0.9824730753898621\n",
      "Epoch 18/100, Loss: 0.981449544429779\n",
      "Epoch 19/100, Loss: 0.9804151058197021\n",
      "Epoch 20/100, Loss: 0.9792637228965759\n",
      "Epoch 21/100, Loss: 0.9782636165618896\n",
      "Epoch 22/100, Loss: 0.9771883487701416\n",
      "Epoch 23/100, Loss: 0.9762433767318726\n",
      "Epoch 24/100, Loss: 0.9752490520477295\n",
      "Epoch 25/100, Loss: 0.9743140935897827\n",
      "Epoch 26/100, Loss: 0.9734176397323608\n",
      "Epoch 27/100, Loss: 0.9725340008735657\n",
      "Epoch 28/100, Loss: 0.9716924428939819\n",
      "Epoch 29/100, Loss: 0.9708399176597595\n",
      "Epoch 30/100, Loss: 0.969989538192749\n",
      "Epoch 31/100, Loss: 0.9692179560661316\n",
      "Epoch 32/100, Loss: 0.9684662818908691\n",
      "Epoch 33/100, Loss: 0.9677782654762268\n",
      "Epoch 34/100, Loss: 0.9671392440795898\n",
      "Epoch 35/100, Loss: 0.9665366411209106\n",
      "Epoch 36/100, Loss: 0.9658278822898865\n",
      "Epoch 37/100, Loss: 0.9650970697402954\n",
      "Epoch 38/100, Loss: 0.9643680453300476\n",
      "Epoch 39/100, Loss: 0.9637595415115356\n",
      "Epoch 40/100, Loss: 0.9631139636039734\n",
      "Epoch 41/100, Loss: 0.962505042552948\n",
      "Epoch 42/100, Loss: 0.9619177579879761\n",
      "Epoch 43/100, Loss: 0.9613721370697021\n",
      "Epoch 44/100, Loss: 0.9608986973762512\n",
      "Epoch 45/100, Loss: 0.960578441619873\n",
      "Epoch 46/100, Loss: 0.9603347778320312\n",
      "Epoch 47/100, Loss: 0.9598119258880615\n",
      "Epoch 48/100, Loss: 0.959294319152832\n",
      "Epoch 49/100, Loss: 0.95867919921875\n",
      "Epoch 50/100, Loss: 0.9581376910209656\n",
      "Epoch 51/100, Loss: 0.9576256275177002\n",
      "Epoch 52/100, Loss: 0.957410454750061\n",
      "Epoch 53/100, Loss: 0.9579406976699829\n",
      "Epoch 54/100, Loss: 0.9575768113136292\n",
      "Epoch 55/100, Loss: 0.9570420384407043\n",
      "Epoch 56/100, Loss: 0.9566362500190735\n",
      "Epoch 57/100, Loss: 0.9562442302703857\n",
      "Epoch 58/100, Loss: 0.9558496475219727\n",
      "Epoch 59/100, Loss: 0.955514132976532\n",
      "Epoch 60/100, Loss: 0.9552122354507446\n",
      "Epoch 61/100, Loss: 0.9553232789039612\n",
      "Epoch 62/100, Loss: 0.9551540613174438\n",
      "Epoch 63/100, Loss: 0.954582691192627\n",
      "Epoch 64/100, Loss: 0.9542649388313293\n",
      "Epoch 65/100, Loss: 0.9539463520050049\n",
      "Epoch 66/100, Loss: 0.9536435008049011\n",
      "Epoch 67/100, Loss: 0.953266978263855\n",
      "Epoch 68/100, Loss: 0.9529446959495544\n",
      "Epoch 69/100, Loss: 0.9531460404396057\n",
      "Epoch 70/100, Loss: 0.9590067863464355\n",
      "Epoch 71/100, Loss: 0.9564753770828247\n",
      "Epoch 72/100, Loss: 0.9537054896354675\n",
      "Epoch 73/100, Loss: 0.9532731771469116\n",
      "Epoch 74/100, Loss: 0.9530833959579468\n",
      "Epoch 75/100, Loss: 0.9527461528778076\n",
      "Epoch 76/100, Loss: 0.9524085521697998\n",
      "Epoch 77/100, Loss: 0.9521812796592712\n",
      "Epoch 78/100, Loss: 0.9519143104553223\n",
      "Epoch 79/100, Loss: 0.9516529440879822\n",
      "Epoch 80/100, Loss: 0.9514952898025513\n",
      "Epoch 81/100, Loss: 0.9515067338943481\n",
      "Epoch 82/100, Loss: 0.9514521360397339\n",
      "Epoch 83/100, Loss: 0.9508959054946899\n",
      "Epoch 84/100, Loss: 0.9507007598876953\n",
      "Epoch 85/100, Loss: 0.9504315257072449\n",
      "Epoch 86/100, Loss: 0.9500694274902344\n",
      "Epoch 87/100, Loss: 0.9497994184494019\n",
      "Epoch 88/100, Loss: 0.9496221542358398\n",
      "Epoch 89/100, Loss: 0.9494005441665649\n",
      "Epoch 90/100, Loss: 0.9491681456565857\n",
      "Epoch 91/100, Loss: 0.948997974395752\n",
      "Epoch 92/100, Loss: 0.9490547776222229\n",
      "Epoch 93/100, Loss: 0.9496530294418335\n",
      "Epoch 94/100, Loss: 0.9491154551506042\n",
      "Epoch 95/100, Loss: 0.9490676522254944\n",
      "Epoch 96/100, Loss: 0.9491241574287415\n",
      "Epoch 97/100, Loss: 0.9490793943405151\n",
      "Epoch 98/100, Loss: 0.9487017393112183\n",
      "Epoch 99/100, Loss: 0.9486015439033508\n",
      "Epoch 100/100, Loss: 0.9483039975166321\n",
      "Output after training: torch.Size([32, 128, 512])\n"
     ]
    }
   ],
   "source": [
    "model = Mamba(num_layers = 6, d_input = 512, d_model = 256)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "input_tensor = torch.randn(32, 128, 512)\n",
    "target_tensor = torch.randn(32, 128, 512)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Прямой проход\n",
    "    output = model(input_tensor)\n",
    "    \n",
    "    # Вычисление потерь\n",
    "    loss = criterion(output, target_tensor)\n",
    "    \n",
    "    # Обратный проход\n",
    "    loss.backward()\n",
    "    \n",
    "    # Обновление параметров модели\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Пример использования обученной модели\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    print(\"Output after training:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343040ed-d7c0-44dc-b864-979db12bc7fc",
   "metadata": {},
   "source": [
    "## Домашнее задание: Обучение и визуализация Mamba\n",
    "\n",
    "### Цель задания\n",
    "\n",
    "1. Обучить простую модель семейства Mamba для обработки любых данных (на выбор: текст, аудио, видео, изображения и ...)\n",
    "2. Визуализировать веса внимания и интерпретировать их\n",
    "3. Сделать выводы о том, как модель воспринимает данные и принимает решения"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
